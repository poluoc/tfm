{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "\n",
    "import random\n",
    "random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn modules\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost (Extreme Gradient Boosting)\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting np random seed\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. \n",
    "However, the positive class has a clear pattern where all the samples are in a corner if we make a scatter plot of the 3 first components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('./data_creditCardFraud.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class distribution\")\n",
    "print(df.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(2), [df.Class.value_counts()[0], df.Class.value_counts()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraud_transacation = df[df[\"Class\"]==1]\n",
    "Normal_transacation= df[df[\"Class\"]==0]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "Fraud_transacation[Fraud_transacation[\"Amount\"]<= 2500].Amount.plot.hist(title=\"Fraud\")\n",
    "plt.subplot(122)\n",
    "Normal_transacation[Normal_transacation[\"Amount\"]<=2500].Amount.plot.hist(title=\"Non-Fraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each fraud transaction can represent a very significant expense, which together can represent billions of dollars of lost revenue each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had a classifier that always predicts that is not Fraud, in this case, we would have a 99.8% of accuracy.\n",
    "We will train a Logistic Regression, a Decision Tree, a Random Forest, a GBM and a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data to Train and Test\n",
    "# We also drop feature time because it is different from every transacion and does not \n",
    "y = df.Class\n",
    "X = df.drop(['Class','Time'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We are maintaining the same training and test data in order to have accurate results.\n",
    "X_test_solution = X_test.copy()\n",
    "y_test_solution = y_test.copy()\n",
    "\n",
    "# we rejoin the training data\n",
    "training_set = X_train.copy()\n",
    "training_set[\"Class\"] = pd.DataFrame(y_train)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set[training_set.Class == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(X_train.columns,logistic_regression.coef_[0])\n",
    "plt.title(\"Coefficient values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = tree.DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier()\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred)*100) + \"%\")\n",
    "print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred)*100) + \"%\")\n",
    "print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred)*100) + \"%\")\n",
    "print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred)*100) + \"%\")\n",
    "print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred)*100) + \"%\")\n",
    "print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred)*100) + \"%\")\n",
    "print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred)*100) + \"%\")\n",
    "print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred)*100) + \"%\")\n",
    "print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred)*100) + \"%\")\n",
    "print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred)*100) + \"%\")\n",
    "print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred)*100) + \"%\")\n",
    "print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred)*100) + \"%\")\n",
    "print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Logistic Regression\")\n",
    "lr_cm = pd.DataFrame(confusion_matrix(y_test, lr_pred))\n",
    "lr_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "lr_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Decision Tree\")\n",
    "dt_cm = pd.DataFrame(confusion_matrix(y_test, dt_pred))\n",
    "dt_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "dt_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Random Forest\")\n",
    "rf_cm = pd.DataFrame(confusion_matrix(y_test, rf_pred))\n",
    "rf_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "rf_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix GBM\")\n",
    "gbm_cm = pd.DataFrame(confusion_matrix(y_test, gbm_pred))\n",
    "gbm_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "gbm_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_pred)\n",
    "auc_lr = roc_auc_score(y_test, lr_pred)\n",
    "plt.plot(fpr_lr,tpr_lr,label=\"Logistic Regression, auc=\"+str(auc_lr))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_pred)\n",
    "auc_dt = roc_auc_score(y_test, dt_pred)\n",
    "plt.plot(fpr_dt,tpr_dt,label=\"Decision Tree, auc=\"+str(auc_dt))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_pred)\n",
    "auc_rf = roc_auc_score(y_test, rf_pred)\n",
    "plt.plot(fpr_rf,tpr_rf,label=\"Random Forest, auc=\"+str(auc_rf))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_regression, open(\"logisticRegression.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(decision_tree, open(\"decisionTree.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(random_forest, open(\"randomForest.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gbm, open(\"gbm.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques to solve the imbalanced datasets problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We are maintaining the same training and test data in order to have accurate results.\n",
    "X_test_solution = X_test.copy()\n",
    "y_test_solution = y_test.copy()\n",
    "\n",
    "# we rejoin the training data\n",
    "training_set = X_train.copy()\n",
    "training_set[\"Class\"] = pd.DataFrame(y_train)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set[training_set.Class == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are reducing the amount of training samples of the majority class in order to create a balanced dataset 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices = training_set[training_set.Class == 1].index\n",
    "normal_indices = training_set[training_set.Class == 0].index\n",
    "\n",
    "under_sample_indices = np.random.choice(normal_indices, len(training_set[training_set.Class == 1]) , False)\n",
    "train_undersampled = training_set.loc[np.concatenate([fraud_indices, under_sample_indices]),:]\n",
    "X_train_undersampled = train_undersampled.iloc[:,0:29]\n",
    "Y_train_undersampled = train_undersampled.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_undersampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length training set\", len(X_train_undersampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training undersampled models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_undersampled = LogisticRegression(solver='liblinear').fit(X_train_undersampled, Y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_undersampled = logistic_regression_undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_undersampled = tree.DecisionTreeClassifier().fit(X_train_undersampled, Y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_undersampled = decision_tree_undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_undersampled = RandomForestClassifier(n_estimators=10).fit(X_train_undersampled, Y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_undersampled = random_forest_undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_undersampled = xgb.XGBClassifier()\n",
    "gbm_undersampled.fit(X_train_undersampled, Y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pred_undersampled = gbm_undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_regression_undersampled, open(\"logisticRegression_undersampled.sav\", 'wb'))\n",
    "pickle.dump(decision_tree_undersampled, open(\"decisionTree_undersampled.sav\", 'wb'))\n",
    "pickle.dump(random_forest_undersampled, open(\"randomForest_undersampled.sav\", 'wb'))\n",
    "pickle.dump(gbm_undersampled, open(\"gbm_undersampled.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred_undersampled)*100) + \"%\")\n",
    "print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred_undersampled)*100) + \"%\")\n",
    "print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred_undersampled)*100) + \"%\")\n",
    "print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred_undersampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred_undersampled)*100) + \"%\")\n",
    "print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred_undersampled)*100) + \"%\")\n",
    "print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred_undersampled)*100) + \"%\")\n",
    "print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred_undersampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred_undersampled)*100) + \"%\")\n",
    "print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred_undersampled)*100) + \"%\")\n",
    "print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred_undersampled)*100) + \"%\")\n",
    "print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred_undersampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred_undersampled)*100) + \"%\")\n",
    "print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred_undersampled)*100) + \"%\")\n",
    "print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred_undersampled)*100) + \"%\")\n",
    "print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred_undersampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Logistic Regression\")\n",
    "lr_cm_undersampled = pd.DataFrame(confusion_matrix(y_test, lr_pred_undersampled))\n",
    "lr_cm_undersampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "lr_cm_undersampled\n",
    "# We are missclassifing 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Decision Tree\")\n",
    "dt_cm_undersampled = pd.DataFrame(confusion_matrix(y_test, dt_pred_undersampled))\n",
    "dt_cm_undersampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "dt_cm_undersampled\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Random Forest\")\n",
    "rf_cm_undersampled = pd.DataFrame(confusion_matrix(y_test, rf_pred_undersampled))\n",
    "rf_cm_undersampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "rf_cm_undersampled\n",
    "# We are missclassifing 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix GBM\")\n",
    "gbm_cm_undersampled = pd.DataFrame(confusion_matrix(y_test, gbm_pred_undersampled))\n",
    "gbm_cm_undersampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "gbm_cm_undersampled\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr_undersampled, tpr_lr_undersampled, _ = roc_curve(y_test, lr_pred_undersampled)\n",
    "auc_lr_undersampled = roc_auc_score(y_test, lr_pred_undersampled)\n",
    "plt.plot(fpr_lr_undersampled,tpr_lr_undersampled,label=\"Logistic Regression, auc=\"+str(auc_lr_undersampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt_undersampled, tpr_dt_undersampled, _ = roc_curve(y_test, dt_pred_undersampled)\n",
    "auc_dt_undersampled = roc_auc_score(y_test, dt_pred_undersampled)\n",
    "plt.plot(fpr_dt_undersampled,tpr_dt_undersampled,label=\"Decision Tree, auc=\"+str(auc_dt_undersampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf_undersampled, tpr_rf_undersampled, _ = roc_curve(y_test, rf_pred_undersampled)\n",
    "auc_rf_undersampled = roc_auc_score(y_test, rf_pred_undersampled)\n",
    "plt.plot(fpr_rf_undersampled,tpr_rf_undersampled,label=\"Random Forest, auc=\"+str(auc_rf_undersampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_gbm_undersampled, tpr_gbm_undersampled, _ = roc_curve(y_test, gbm_pred_undersampled)\n",
    "auc_gbm_undersampled = roc_auc_score(y_test, gbm_pred_undersampled)\n",
    "plt.plot(fpr_gbm_undersampled,tpr_gbm_undersampled,label=\"GBM, auc=\"+str(auc_gbm_undersampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Oversampling (brute force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create copies from the minority class in order to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_indices_len = len(training_set[training_set.Class == 1].index)\n",
    "normal_indices_len = len(training_set[training_set.Class == 0].index)\n",
    "\n",
    "train_oversampled = training_set[training_set.Class == 0]\n",
    "fraud_samples = training_set[training_set.Class == 1]\n",
    "\n",
    "i = 0\n",
    "total_copies = int(normal_indices_len/fraud_indices_len)\n",
    "while i < total_copies:\n",
    "    frames = [train_oversampled, fraud_samples]\n",
    "    train_oversampled = pd.concat(frames)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning all rows in random order\n",
    "train_oversampled = train_oversampled.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversampled = train_oversampled.iloc[:,0:29]\n",
    "Y_train_oversampled = train_oversampled.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking same number of samples per class\n",
    "train_oversampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training oversampled models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_oversampled = LogisticRegression(solver='liblinear').fit(X_train_oversampled, Y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_oversampled = logistic_regression_oversampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_oversampled = tree.DecisionTreeClassifier().fit(X_train_oversampled, Y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_oversampled = decision_tree_oversampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_oversampled = RandomForestClassifier(n_estimators=10).fit(X_train_oversampled, Y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_oversampled = random_forest_oversampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_oversampled = xgb.XGBClassifier()\n",
    "gbm_oversampled.fit(X_train_oversampled, Y_train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pred_oversampled = gbm_oversampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_regression_oversampled, open(\"logisticRegression_oversampled_bruteForce.sav\", 'wb'))\n",
    "pickle.dump(decision_tree_oversampled, open(\"decisionTree_oversampled_bruteForce.sav\", 'wb'))\n",
    "pickle.dump(random_forest_oversampled, open(\"randomForest_oversampled_bruteForce.sav\", 'wb'))\n",
    "pickle.dump(gbm_oversampled, open(\"gbm_oversampled_bruteForce.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred_oversampled)*100) + \"%\")\n",
    "print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred_oversampled)*100) + \"%\")\n",
    "print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred_oversampled)*100) + \"%\")\n",
    "print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred_oversampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred_oversampled)*100) + \"%\")\n",
    "print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred_oversampled)*100) + \"%\")\n",
    "print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred_oversampled)*100) + \"%\")\n",
    "print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred_oversampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred_oversampled)*100) + \"%\")\n",
    "print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred_oversampled)*100) + \"%\")\n",
    "print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred_oversampled)*100) + \"%\")\n",
    "print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred_oversampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred_oversampled)*100) + \"%\")\n",
    "print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred_oversampled)*100) + \"%\")\n",
    "print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred_oversampled)*100) + \"%\")\n",
    "print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred_oversampled)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Logistic Regression\")\n",
    "lr_cm_oversampled = pd.DataFrame(confusion_matrix(y_test, lr_pred_oversampled))\n",
    "lr_cm_oversampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "lr_cm_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Decision Tree\")\n",
    "dt_cm_oversampled = pd.DataFrame(confusion_matrix(y_test, dt_pred_oversampled))\n",
    "dt_cm_oversampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "dt_cm_oversampled\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Random Forest\")\n",
    "rf_cm_oversampled = pd.DataFrame(confusion_matrix(y_test, rf_pred_oversampled))\n",
    "rf_cm_oversampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "rf_cm_oversampled\n",
    "# We are missclassifing 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix GBM\")\n",
    "gbm_cm_oversampled = pd.DataFrame(confusion_matrix(y_test, gbm_pred_oversampled))\n",
    "gbm_cm_oversampled.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "gbm_cm_oversampled\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC/UAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr_oversampled, tpr_lr_oversampled, _ = roc_curve(y_test, lr_pred_oversampled)\n",
    "auc_lr_oversampled = roc_auc_score(y_test, lr_pred_oversampled)\n",
    "plt.plot(fpr_lr_oversampled,tpr_lr_oversampled,label=\"Logistic Regression, auc=\"+str(auc_lr_oversampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt_oversampled, tpr_dt_oversampled, _ = roc_curve(y_test, dt_pred_oversampled)\n",
    "auc_dt_oversampled = roc_auc_score(y_test, dt_pred_oversampled)\n",
    "plt.plot(fpr_dt_oversampled,tpr_dt_oversampled,label=\"Decision Tree, auc=\"+str(auc_dt_oversampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf_oversampled, tpr_rf_oversampled, _ = roc_curve(y_test, rf_pred_oversampled)\n",
    "auc_rf_oversampled = roc_auc_score(y_test, rf_pred_oversampled)\n",
    "plt.plot(fpr_rf_oversampled,tpr_rf_oversampled,label=\"Random Forest, auc=\"+str(auc_rf_oversampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr_gbm_oversampled, tpr_gbm_oversampled, _ = roc_curve(y_test, gbm_pred_oversampled)\n",
    "auc_gbm_oversampled = roc_auc_score(y_test, gbm_pred_oversampled)\n",
    "plt.plot(fpr_gbm_oversampled,tpr_gbm_oversampled,label=\"GBM, auc=\"+str(auc_gbm_oversampled))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Oversampling v2 (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create copies from the minority class in order to balance the dataset with sklearn resample module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = training_set[training_set.Class == 1]\n",
    "normal_df = training_set[training_set.Class == 0]\n",
    "\n",
    "# upsample minority\n",
    "fraud_oversampled_df = resample(fraud_df,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(normal_df), # match number in majority class\n",
    "                          random_state=777)\n",
    "\n",
    "# Join both fraud and normal dataframes\n",
    "train_oversampled_v2 = pd.concat([normal_df, fraud_oversampled_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking same number of samples per class\n",
    "train_oversampled_v2.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning all rows in random order\n",
    "train_oversampled_v2 = train_oversampled_v2.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversampled_v2 = train_oversampled_v2.iloc[:,0:29]\n",
    "Y_train_oversampled_v2 = train_oversampled_v2.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversampled_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training oversampled models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_oversampled_v2 = LogisticRegression(solver='liblinear').fit(X_train_oversampled_v2, Y_train_oversampled_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_oversampled_v2 = logistic_regression_oversampled_v2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_oversampled_v2 = tree.DecisionTreeClassifier().fit(X_train_oversampled_v2, Y_train_oversampled_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_oversampled_v2 = decision_tree_oversampled_v2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_oversampled_v2 = RandomForestClassifier(n_estimators=10).fit(X_train_oversampled_v2, Y_train_oversampled_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_oversampled_v2 = random_forest_oversampled_v2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_oversampled_v2 = xgb.XGBClassifier()\n",
    "gbm_oversampled_v2.fit(X_train_oversampled_v2, Y_train_oversampled_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pred_oversampled_v2 = gbm_oversampled_v2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_regression_oversampled_v2, open(\"logisticRegression_oversampled_v2.sav\", 'wb'))\n",
    "pickle.dump(decision_tree_oversampled_v2, open(\"decisionTree_oversampled_v2.sav\", 'wb'))\n",
    "pickle.dump(random_forest_oversampled_v2, open(\"randomForest_oversampled_v2.sav\", 'wb'))\n",
    "pickle.dump(gbm_oversampled_v2, open(\"gbm_oversampled_v2.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred_oversampled_v2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred_oversampled_v2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred_oversampled_v2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred_oversampled_v2)*100) + \"%\")\n",
    "print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred_oversampled_v2)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Logistic Regression\")\n",
    "lr_cm_oversampled_v2 = pd.DataFrame(confusion_matrix(y_test, lr_pred_oversampled_v2))\n",
    "lr_cm_oversampled_v2.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "lr_cm_oversampled_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Decision Tree\")\n",
    "dt_cm_oversampled_v2 = pd.DataFrame(confusion_matrix(y_test, dt_pred_oversampled_v2))\n",
    "dt_cm_oversampled_v2.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "dt_cm_oversampled_v2\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Random Forest\")\n",
    "rf_cm_oversampled_v2 = pd.DataFrame(confusion_matrix(y_test, rf_pred_oversampled_v2))\n",
    "rf_cm_oversampled_v2.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "rf_cm_oversampled_v2\n",
    "# We are missclassifing 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix GBM\")\n",
    "gbm_cm_oversampled_v2 = pd.DataFrame(confusion_matrix(y_test, gbm_pred_oversampled_v2))\n",
    "gbm_cm_oversampled_v2.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "gbm_cm_oversampled_v2\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC/UAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr_oversampled_v2, tpr_lr_oversampled_v2, _ = roc_curve(y_test, lr_pred_oversampled_v2)\n",
    "auc_lr_oversampled_v2 = roc_auc_score(y_test, lr_pred_oversampled_v2)\n",
    "plt.plot(fpr_lr_oversampled_v2,tpr_lr_oversampled_v2,label=\"Logistic Regression, auc=\"+str(auc_lr_oversampled_v2))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt_oversampled_v2, tpr_dt_oversampled_v2, _ = roc_curve(y_test, dt_pred_oversampled_v2)\n",
    "auc_dt_oversampled_v2 = roc_auc_score(y_test, dt_pred_oversampled_v2)\n",
    "plt.plot(fpr_dt_oversampled_v2,tpr_dt_oversampled_v2,label=\"Decision Tree, auc=\"+str(auc_dt_oversampled_v2))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf_oversampled_v2, tpr_rf_oversampled_v2, _ = roc_curve(y_test, rf_pred_oversampled_v2)\n",
    "auc_rf_oversampled_v2 = roc_auc_score(y_test, rf_pred_oversampled_v2)\n",
    "plt.plot(fpr_rf_oversampled_v2,tpr_rf_oversampled_v2,label=\"Random Forest, auc=\"+str(auc_rf_oversampled_v2))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr_gbm_oversampled_v2, tpr_gbm_oversampled_v2, _ = roc_curve(y_test, gbm_pred_oversampled_v2)\n",
    "auc_gbm_oversampled_v2 = roc_auc_score(y_test, gbm_pred_oversampled_v2)\n",
    "plt.plot(fpr_gbm_oversampled_v2,tpr_gbm_oversampled_v2,label=\"GBM, auc=\"+str(auc_gbm_oversampled_v2))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create syntethic copies from the minority class in order to balance the dataset. This technique is called SMOTE or Synthetic Minority Oversampling Technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the training set\n",
    "sm = SMOTE(random_state=777, sampling_strategy=1.0)\n",
    "X_train_oversampled_syntethic, Y_train_oversampled_syntethic = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking same number of samples per class\n",
    "pd.DataFrame(Y_train_oversampled_syntethic).Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversampled_syntethic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training oversampled models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_oversampled_syntethic = LogisticRegression(solver='liblinear').fit(X_train_oversampled_syntethic, Y_train_oversampled_syntethic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_oversampled_syntethic = logistic_regression_oversampled_syntethic.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_oversampled_syntethic = tree.DecisionTreeClassifier().fit(X_train_oversampled_syntethic, Y_train_oversampled_syntethic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_oversampled_syntethic = decision_tree_oversampled_syntethic.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_oversampled_syntethic = RandomForestClassifier(n_estimators=10).fit(X_train_oversampled_syntethic, Y_train_oversampled_syntethic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_oversampled_syntethic = random_forest_oversampled_syntethic.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_oversampled_syntethic = xgb.XGBClassifier()\n",
    "gbm_oversampled_syntethic.fit(X_train_oversampled_syntethic, Y_train_oversampled_syntethic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_pred_oversampled_syntethic = gbm_oversampled_syntethic.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logistic_regression_oversampled_syntethic, open(\"logisticRegression_oversampled_syntethic.sav\", 'wb'))\n",
    "pickle.dump(decision_tree_oversampled_syntethic, open(\"decisionTree_oversampled_syntethic.sav\", 'wb'))\n",
    "pickle.dump(random_forest_oversampled_syntethic, open(\"randomForest_oversampled_syntethic.sav\", 'wb'))\n",
    "pickle.dump(gbm_oversampled_syntethic, open(\"gbm_oversampled_syntethic.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred_oversampled_syntethic)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred_oversampled_syntethic)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred_oversampled_syntethic)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred_oversampled_syntethic)*100) + \"%\")\n",
    "print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred_oversampled_syntethic)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Logistic Regression\")\n",
    "lr_cm_oversampled_syntethic = pd.DataFrame(confusion_matrix(y_test, lr_pred_oversampled_syntethic))\n",
    "lr_cm_oversampled_syntethic.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "lr_cm_oversampled_syntethic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Decision Tree\")\n",
    "dt_cm_oversampled_syntethic = pd.DataFrame(confusion_matrix(y_test, dt_pred_oversampled_syntethic))\n",
    "dt_cm_oversampled_syntethic.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "dt_cm_oversampled_syntethic\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix Random Forest\")\n",
    "rf_cm_oversampled_syntethic = pd.DataFrame(confusion_matrix(y_test, rf_pred_oversampled_syntethic))\n",
    "rf_cm_oversampled_syntethic.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "rf_cm_oversampled_syntethic\n",
    "# We are missclassifing 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix GBM\")\n",
    "gbm_cm_oversampled_syntethic = pd.DataFrame(confusion_matrix(y_test, gbm_pred_oversampled_syntethic))\n",
    "gbm_cm_oversampled_syntethic.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "gbm_cm_oversampled_syntethic\n",
    "# We are missclassifing 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC/UAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr_oversampled_syntethic, tpr_lr_oversampled_syntethic, _ = roc_curve(y_test, lr_pred_oversampled_syntethic)\n",
    "auc_lr_oversampled_syntethic = roc_auc_score(y_test, lr_pred_oversampled_syntethic)\n",
    "plt.plot(fpr_lr_oversampled_syntethic,tpr_lr_oversampled_syntethic,label=\"Logistic Regression, auc=\"+str(auc_lr_oversampled_syntethic))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dt_oversampled_syntethic, tpr_dt_oversampled_syntethic, _ = roc_curve(y_test, dt_pred_oversampled_syntethic)\n",
    "auc_dt_oversampled_syntethic = roc_auc_score(y_test, dt_pred_oversampled_syntethic)\n",
    "plt.plot(fpr_dt_oversampled_syntethic,tpr_dt_oversampled_syntethic,label=\"Decision Tree, auc=\"+str(auc_dt_oversampled_syntethic))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf_oversampled_syntethic, tpr_rf_oversampled_syntethic, _ = roc_curve(y_test, rf_pred_oversampled_syntethic)\n",
    "auc_rf_oversampled_syntethic = roc_auc_score(y_test, rf_pred_oversampled_syntethic)\n",
    "plt.plot(fpr_rf_oversampled_syntethic,tpr_rf_oversampled_syntethic,label=\"Random Forest, auc=\"+str(auc_rf_oversampled_syntethic))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr_gbm_oversampled_syntethic, tpr_gbm_oversampled_syntethic, _ = roc_curve(y_test, gbm_pred_oversampled_syntethic)\n",
    "auc_gbm_oversampled_syntethic = roc_auc_score(y_test, gbm_pred_oversampled_syntethic)\n",
    "plt.plot(fpr_gbm_oversampled_syntethic,tpr_gbm_oversampled_syntethic,label=\"GBM, auc=\"+str(auc_gbm_oversampled_syntethic))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Ensembling L different models with a resampled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build N models, in this example 5, 10, 20 and 50, where every model has all the training data from the minority class and N/10 samples of the majority. Then, the prediction will be accorded between all the models having all of them the same weigth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average prediction of N list predictions with everyone having the same weight.\n",
    "# where X is a list of arrays\n",
    "# maybe can be imrpvoed using np.average([array_1, array_2], axis=0, weights=[weight_1, weight_2])\n",
    "def calculate_weighted_prediction(lista):\n",
    "    res = 0\n",
    "    for i in range(0,len(lista)):\n",
    "        weight = 1/len(lista)\n",
    "        res += weight*lista[i]\n",
    "    return (res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembleMethod(N, training_set):\n",
    "    \n",
    "    # We divide the training set in oredr to be able to make different datasets\n",
    "    fraud_samples = training_set[training_set.Class == 1]\n",
    "    normal_samples = training_set[training_set.Class == 0]\n",
    "    \n",
    "    new_length = int(len(normal_samples)/N)\n",
    "    training_ensemble = []\n",
    "    X_train_ensemble = []\n",
    "    Y_train_ensemble = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < N:\n",
    "        new_frames = [fraud_samples, pd.DataFrame(normal_samples[i*new_length:(i+1)*new_length])]\n",
    "        tmp = pd.concat(new_frames)\n",
    "        training_ensemble.append(tmp)\n",
    "        # Random order\n",
    "        training_ensemble[i] = training_ensemble[i].sample(frac=1)\n",
    "        # Dividing X and Y\n",
    "        tmp = training_ensemble[i].iloc[:,0:29]\n",
    "        X_train_ensemble.append(tmp)\n",
    "        tmp = training_ensemble[i].Class\n",
    "        Y_train_ensemble.append(tmp)\n",
    "        i += 1\n",
    "\n",
    "    # Training models\n",
    "    n = 0\n",
    "    logistic_regression_ensemble = []\n",
    "    decision_tree_ensemble = []\n",
    "    random_forest_ensemble = []\n",
    "    gbm_ensemble = []\n",
    "    while n < N:\n",
    "        # Logistic Regression\n",
    "        tmp = LogisticRegression(solver='liblinear').fit(X_train_ensemble[n],Y_train_ensemble[n])\n",
    "        logistic_regression_ensemble.append(tmp)\n",
    "        # Decision Tree\n",
    "        tmp = tree.DecisionTreeClassifier().fit(X_train_ensemble[n],Y_train_ensemble[n])\n",
    "        decision_tree_ensemble.append(tmp)\n",
    "        # Random Forest\n",
    "        tmp = RandomForestClassifier(n_estimators=10).fit(X_train_ensemble[n],Y_train_ensemble[n])\n",
    "        random_forest_ensemble.append(tmp)\n",
    "        # GBM\n",
    "        tmp = xgb.XGBClassifier()\n",
    "        tmp.fit(X_train_ensemble[n],Y_train_ensemble[n])      \n",
    "        gbm_ensemble.append(tmp)\n",
    "        n += 1\n",
    "     \n",
    "    # Saving models\n",
    "    pickle.dump(logistic_regression_ensemble, open(\"models_2080/logisticRegression_ensemble1_\" + str(N) + \".sav\", 'wb'))\n",
    "    pickle.dump(decision_tree_ensemble, open(\"models_2080/decisionTree_ensemble1_\" + str(N) + \".sav\", 'wb'))\n",
    "    pickle.dump(random_forest_ensemble, open(\"models_2080/randomForest_ensemble1_\" + str(N) + \".sav\", 'wb'))\n",
    "    pickle.dump(gbm_ensemble, open(\"models_2080/gbm_ensemble1_\" + str(N) + \".sav\", 'wb'))\n",
    "    \n",
    "    # Predicting with each model\n",
    "    n = 0\n",
    "    lr_pred_ensemble = []\n",
    "    rf_pred_ensemble = []\n",
    "    dt_pred_ensemble = []\n",
    "    gbm_pred_ensemble = []\n",
    "    while n < N:\n",
    "        # Logistic Regression\n",
    "        tmp = logistic_regression_ensemble[n].predict(X_test)\n",
    "        lr_pred_ensemble.append(tmp)\n",
    "        # Decision Tree\n",
    "        tmp = decision_tree_ensemble[n].predict(X_test)\n",
    "        dt_pred_ensemble.append(tmp)\n",
    "        # Random Forest\n",
    "        tmp = random_forest_ensemble[n].predict(X_test)\n",
    "        rf_pred_ensemble.append(tmp)\n",
    "        # GBM\n",
    "        tmp = gbm_ensemble[n].predict(X_test)\n",
    "        gbm_pred_ensemble.append(tmp)\n",
    "        n += 1\n",
    "        \n",
    "    # Calculate average prediction\n",
    "    lr_pred_ensemble_total = calculate_weighted_prediction(lr_pred_ensemble)\n",
    "    dt_pred_ensemble_total = calculate_weighted_prediction(dt_pred_ensemble)\n",
    "    rf_pred_ensemble_total = calculate_weighted_prediction(rf_pred_ensemble)\n",
    "    gbm_pred_ensemble_total = calculate_weighted_prediction(gbm_pred_ensemble)\n",
    "    \n",
    "    # Results\n",
    "    print(\"************************* RESULTS *************************\")\n",
    "    print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Logistic Regression Ensemble \" + str(N))\n",
    "    lr_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, lr_pred_ensemble_total))\n",
    "    lr_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(lr_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, lr_pred_ensemble_total))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Decision Tree Ensemble \" + str(N))\n",
    "    dt_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, dt_pred_ensemble_total))\n",
    "    dt_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(dt_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, dt_pred_ensemble_total))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Random Forest Ensemble \" + str(N))\n",
    "    rf_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, rf_pred_ensemble_total))\n",
    "    rf_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(rf_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, rf_pred_ensemble_total))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix GBM Ensemble \" + str(N))\n",
    "    gbm_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, gbm_pred_ensemble_total))\n",
    "    gbm_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(gbm_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, gbm_pred_ensemble_total))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(2, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(3, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(5, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(7, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(10, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(15, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(20, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(27, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(35, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(50, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(100, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(250, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(500, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(750, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod(1000, training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ensembling L different models with different ratios of a resampled dataset with an equal weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build N models where every model has all the training data from the minority class and different ratios [(1,1),(1,1.5),(1,2),(1,3),(1,4),(1,5),(1,7.5),(1,10),(2,1),(3,1)] from the majority class.For instance, if we make 5 models, we could make 1:1, 1:10, 2:1, (1:5) and (3,1). We are picking randomly the ratios in order to validate the hypothesis (if picking all or doing distribution, will take too much time).\n",
    "Then, the prediction will be accorded between all the models having all of them the same weigth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the average prediction of N list predictions with everyone having the same weight.\n",
    "# where X is a list of arrays\n",
    "# maybe can be imrpvoed using np.average([array_1, array_2], axis=0, weights=[weight_1, weight_2])\n",
    "def calculate_weighted_prediction(lista):\n",
    "    res = 0\n",
    "    for i in range(0,len(lista)):\n",
    "        weight = 1/len(lista)\n",
    "        res += weight*lista[i]\n",
    "    return (res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N max = 10\n",
    "# We are picking random \n",
    "def ensembleMethod_2(N, training_set):\n",
    "    \n",
    "    if N > 10 or N < 2:\n",
    "        return \"Maximum N value is 10 and minimum is 2.\"\n",
    "    \n",
    "    # (rare/abundant)\n",
    "    ratios = np.array(([1,1],[1,1.5],[1,2],[1,3],[1,4],[1,5],[1,7.5],[1,10],[2,1],[3,1]))\n",
    "    random_samples = random.choices(ratios, k=N)\n",
    "\n",
    "    # We divide the training set in oredr to be able to make different datasets\n",
    "    fraud_samples = training_set[training_set.Class == 1]\n",
    "    normal_samples = training_set[training_set.Class == 0]\n",
    "    \n",
    "    # Having this high imbalance, we will never achieve a limit with the majority class\n",
    "    # However, if it happens, we should duplicate the majority class samples with different models; \n",
    "    # for instance, Model A from 1 to 8, model B from 9 to 13, model C from 14 to 8; like a wheel :)\n",
    "        \n",
    "    \n",
    "    training_ensemble = []\n",
    "    X_train_ensemble = []\n",
    "    Y_train_ensemble = []\n",
    "    start_majority_class = 0\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        # fraud and normal samples distribution\n",
    "        new_length_normal_samples = int(ratios[i][1]*len(fraud_samples) + start_majority_class)\n",
    "        # in fraud we only duplicate or triplicate, so\n",
    "        if ratios[i][0] == 2:\n",
    "            tmp_fraud_samples = pd.concat([fraud_samples, fraud_samples])\n",
    "        elif ratios[i][0] == 3:\n",
    "            tmp_fraud_samples = pd.concat([fraud_samples, fraud_samples, fraud_samples])\n",
    "        else:\n",
    "            tmp_fraud_samples = fraud_samples\n",
    "        # we create the new dataset\n",
    "        new_frames = [tmp_fraud_samples, pd.DataFrame(normal_samples[start_majority_class:new_length_normal_samples])]\n",
    "        tmp = pd.concat(new_frames)\n",
    "        training_ensemble.append(tmp)\n",
    "        # Random order\n",
    "        training_ensemble[i] = training_ensemble[i].sample(frac=1)\n",
    "        # Dividing X and Y\n",
    "        tmp = training_ensemble[i].iloc[:,0:29]\n",
    "        X_train_ensemble.append(tmp)\n",
    "        tmp = training_ensemble[i].Class\n",
    "        Y_train_ensemble.append(tmp)\n",
    "        \n",
    "        start_majority_class = new_length_normal_samples + 1\n",
    "        i += 1\n",
    "\n",
    "    # Training models, each model has all different datasets and then the prediction is weighted\n",
    "    n = 0\n",
    "    logistic_regression_ensemble = []\n",
    "    decision_tree_ensemble = []\n",
    "    random_forest_ensemble = []\n",
    "    gbm_ensemble = []\n",
    "    while n < N:\n",
    "        # Logistic Regression\n",
    "        tmp = LogisticRegression(solver='liblinear').fit(X_train_ensemble[n],Y_train_ensemble[n])\n",
    "        logistic_regression_ensemble.append(tmp)\n",
    "        # Decision Tree\n",
    "        tmp = tree.DecisionTreeClassifier().fit(X_train_ensemble[n],Y_train_ensemble[n])\n",
    "        decision_tree_ensemble.append(tmp)\n",
    "        # Random Forest\n",
    "        tmp = RandomForestClassifier(n_estimators=10).fit(X_train_ensemble[n],Y_train_ensemble[n])\n",
    "        random_forest_ensemble.append(tmp)\n",
    "        # GBM\n",
    "        tmp = xgb.XGBClassifier()\n",
    "        tmp.fit(X_train_ensemble[n],Y_train_ensemble[n])      \n",
    "        gbm_ensemble.append(tmp)\n",
    "        n += 1\n",
    "     \n",
    "    # Saving models\n",
    "    pickle.dump(logistic_regression_ensemble, open(\"models_2080/logisticRegression_ensemble2_\" + str(N) + \".sav\", 'wb'))\n",
    "    pickle.dump(decision_tree_ensemble, open(\"models_2080/decisionTree_ensemble2_\" + str(N) + \".sav\", 'wb'))\n",
    "    pickle.dump(random_forest_ensemble, open(\"models_2080/randomForest_ensemble2_\" + str(N) + \".sav\", 'wb'))\n",
    "    pickle.dump(gbm_ensemble, open(\"models_2080/gbm_ensemble2_\" + str(N) + \".sav\", 'wb'))\n",
    "    \n",
    "    # Predicting with each model\n",
    "    n = 0\n",
    "    lr_pred_ensemble = []\n",
    "    rf_pred_ensemble = []\n",
    "    dt_pred_ensemble = []\n",
    "    gbm_pred_ensemble = []\n",
    "    while n < N:\n",
    "        # Logistic Regression\n",
    "        tmp = logistic_regression_ensemble[n].predict(X_test)\n",
    "        lr_pred_ensemble.append(tmp)\n",
    "        # Decision Tree\n",
    "        tmp = decision_tree_ensemble[n].predict(X_test)\n",
    "        dt_pred_ensemble.append(tmp)\n",
    "        # Random Forest\n",
    "        tmp = random_forest_ensemble[n].predict(X_test)\n",
    "        rf_pred_ensemble.append(tmp)\n",
    "        # GBM\n",
    "        tmp = gbm_ensemble[n].predict(X_test)\n",
    "        gbm_pred_ensemble.append(tmp)\n",
    "        n += 1\n",
    "        \n",
    "    # Calculate average prediction\n",
    "    lr_pred_ensemble_total = calculate_weighted_prediction(lr_pred_ensemble)\n",
    "    dt_pred_ensemble_total = calculate_weighted_prediction(dt_pred_ensemble)\n",
    "    rf_pred_ensemble_total = calculate_weighted_prediction(rf_pred_ensemble)\n",
    "    gbm_pred_ensemble_total = calculate_weighted_prediction(gbm_pred_ensemble)\n",
    "    \n",
    "    # Results\n",
    "    print(\"************************* RESULTS *************************\")\n",
    "    print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred_ensemble_total)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Logistic Regression Ensemble2 \" + str(N))\n",
    "    lr_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, lr_pred_ensemble_total))\n",
    "    lr_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(lr_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, lr_pred_ensemble_total))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Decision Tree Ensemble2 \" + str(N))\n",
    "    dt_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, dt_pred_ensemble_total))\n",
    "    dt_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(dt_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, dt_pred_ensemble_total))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Random Forest Ensemble2 \" + str(N))\n",
    "    rf_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, rf_pred_ensemble_total))\n",
    "    rf_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(rf_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, rf_pred_ensemble_total))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix GBM Ensemble2 \" + str(N))\n",
    "    gbm_cm_ensemble = pd.DataFrame(confusion_matrix(y_test, gbm_pred_ensemble_total))\n",
    "    gbm_cm_ensemble.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(gbm_cm_ensemble)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, gbm_pred_ensemble_total))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(2, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(3, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(4, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(5, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(6, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(7, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(8, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(9, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleMethod_2(10, training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ensembling L different models with different ratios of a resampled dataset with different weights (Suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe this can be done, altough we have validate it our hyptohestis with an equal weigth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Clustering the majority class in R groups and using the center of it to the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to cluster the majority class in R groups, being R => n of minority class samples. In this example, R will be from the same number of the minority class (\"like undersampling but with the medoid) to R*500. \n",
    "(R, 2R, 3R... 500R)\n",
    "\n",
    "This decision/premise has been decided due to computation problems; doing the KMedoids in a large dataset consumes a lot of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringMethod(R, training_set):\n",
    "    if R > 500 or R < 1:\n",
    "        return \"R must be between 1 and 500.\"\n",
    "    \n",
    "    fraud_samples = training_set[training_set.Class == 1]\n",
    "    normal_samples = training_set[training_set.Class == 0]\n",
    "    \n",
    "    # As we set the minum value of R which is the same number of the minority class, we can divide our data \n",
    "    # creating clusters of the min samples n and then  we will create X cluster in function of R. \n",
    "    new_normal_samples_medoid = pd.DataFrame()\n",
    "    start = 0\n",
    "    size = int(len(normal_samples)/len(fraud_samples)) \n",
    "    for i in range(0,len(fraud_samples)):\n",
    "        tmp = pd.DataFrame(normal_samples[start:(start+size-1)])\n",
    "        start = start + size\n",
    "        kmedoids = KMedoids(n_clusters=R, random_state=777).fit(tmp)\n",
    "        centers = kmedoids.cluster_centers_    \n",
    "        for y in centers:\n",
    "            new_normal_samples_medoid = new_normal_samples_medoid.append(\n",
    "                pd.DataFrame(y.reshape(1,-1), columns=list(normal_samples)), ignore_index=True)\n",
    "                       \n",
    "    # Here we have all the medioids, so we join the dataset in order to start training \n",
    "    new_frames = [fraud_samples, new_normal_samples_medoid]\n",
    "    training_set_cluster = pd.concat(new_frames)  \n",
    "    # Random order\n",
    "    training_set_cluster = training_set_cluster.sample(frac=1)\n",
    "    # Dividing X and Y\n",
    "    X_train_clustering = training_set_cluster.iloc[:,0:29]\n",
    "    Y_train_clustering = training_set_cluster.Class\n",
    "    \n",
    "    # Now we train the models\n",
    "    ##### Logistic regression\n",
    "    logistic_regression = LogisticRegression(solver='liblinear').fit(X_train_clustering, Y_train_clustering)\n",
    "    lr_pred = logistic_regression.predict(X_test)\n",
    "    ##### Decision Tree\n",
    "    decision_tree = tree.DecisionTreeClassifier().fit(X_train_clustering, Y_train_clustering)\n",
    "    dt_pred = decision_tree.predict(X_test)\n",
    "    ##### Random Forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=10).fit(X_train_clustering, Y_train_clustering)\n",
    "    rf_pred = random_forest.predict(X_test)\n",
    "    ##### GBM\n",
    "    gbm = xgb.XGBClassifier()\n",
    "    gbm.fit(X_train_clustering, Y_train_clustering)\n",
    "    gbm_pred = gbm.predict(X_test)\n",
    "    \n",
    "    # Saving Models\n",
    "    pickle.dump(logistic_regression, open(\"models_2080/logisticRegression_clusteredR\" + str(R) + \".sav\", 'wb'))\n",
    "    pickle.dump(decision_tree, open(\"models_2080/decisionTree_clustered\" + str(R) + \".sav\", 'wb'))\n",
    "    pickle.dump(random_forest, open(\"models_2080/randomForest_clustered\" + str(R) + \".sav\", 'wb'))\n",
    "    pickle.dump(gbm, open(\"models_2080/gbm_clustered\" + str(R) + \".sav\", 'wb'))\n",
    "    \n",
    "    # Results\n",
    "    print(\"************************* RESULTS *************************\")\n",
    "    print(\"Accuracy Logistic Regression:\", str(accuracy_score(y_test, lr_pred)*100) + \"%\")\n",
    "    print(\"Accuracy Decision Tree:\", str(accuracy_score(y_test, dt_pred)*100) + \"%\")\n",
    "    print(\"Accuracy Random Forest:\", str(accuracy_score(y_test, rf_pred)*100) + \"%\")\n",
    "    print(\"Accuracy GBM:\", str(accuracy_score(y_test, gbm_pred)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"F1 Score Logistic Regression:\", str(f1_score(y_test, lr_pred)*100) + \"%\")\n",
    "    print(\"F1 Score Decision Tree:\", str(f1_score(y_test, dt_pred)*100) + \"%\")\n",
    "    print(\"F1 Score Random Forest:\", str(f1_score(y_test, rf_pred)*100) + \"%\")\n",
    "    print(\"F1 Score GBM:\", str(f1_score(y_test, gbm_pred)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Precision Logistic Regression:\", str(precision_score(y_test, lr_pred)*100) + \"%\")\n",
    "    print(\"Precision Decision Tree:\", str(precision_score(y_test, dt_pred)*100) + \"%\")\n",
    "    print(\"Precision Random Forest:\", str(precision_score(y_test, rf_pred)*100) + \"%\")\n",
    "    print(\"Precision GBM:\", str(precision_score(y_test, gbm_pred)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Recall Logistic Regression:\", str(recall_score(y_test, lr_pred)*100) + \"%\")\n",
    "    print(\"Recall Decision Tree:\", str(recall_score(y_test, dt_pred)*100) + \"%\")\n",
    "    print(\"Recall Random Forest:\", str(recall_score(y_test, rf_pred)*100) + \"%\")\n",
    "    print(\"Recall GBM:\", str(recall_score(y_test, gbm_pred)*100) + \"%\")\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Logistic Regression Clustering \" + str(R))\n",
    "    lr_cm = pd.DataFrame(confusion_matrix(y_test, lr_pred))\n",
    "    lr_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(lr_cm)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, lr_pred))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Decision Tree Clustering \" + str(R))\n",
    "    dt_cm = pd.DataFrame(confusion_matrix(y_test, dt_pred))\n",
    "    dt_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(dt_cm)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, dt_pred))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix Random Forest Clustering \" + str(R))\n",
    "    rf_cm = pd.DataFrame(confusion_matrix(y_test, rf_pred))\n",
    "    rf_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(rf_cm)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, rf_pred))\n",
    "    print(\"\")\n",
    "    print(\"Confusion Matrix GBM Clustering \" + str(R))\n",
    "    gbm_cm = pd.DataFrame(confusion_matrix(y_test, gbm_pred))\n",
    "    gbm_cm.columns = [\"Predicted Not Fraud\",\"Predicted Fraud\"]\n",
    "    print(gbm_cm)\n",
    "    print(\"AUC:\", roc_auc_score(y_test, gbm_pred))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i < 11:\n",
    "    clusteringMethod(i, training_set)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteringMethod(15, training_set)\n",
    "clusteringMethod(25, training_set)\n",
    "clusteringMethod(50, training_set)\n",
    "clusteringMethod(75, training_set)\n",
    "clusteringMethod(100, training_set)\n",
    "clusteringMethod(200, training_set)\n",
    "clusteringMethod(300, training_set)\n",
    "clusteringMethod(400, training_set)\n",
    "clusteringMethod(500, training_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
